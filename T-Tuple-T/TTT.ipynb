{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/vllm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-10 01:55:20,622\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR 12-10 01:55:21 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.\n",
      "INFO 12-10 01:55:21 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory\n",
      "INFO 12-10 01:55:21 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.\n"
     ]
    }
   ],
   "source": [
    "from wayne_utils import load_data, save_data\n",
    "from llm_inferencer import Register, Inferencer\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "_ROOT_PATH = \"/home/jiangpeiwen2/jiangpeiwen2/T-Tuple-T\"\n",
    "\n",
    "test_path = os.path.join( _ROOT_PATH, \"data/test.json\")\n",
    "train_path = os.path.join( _ROOT_PATH, \"data/train.json\")\n",
    "\n",
    "test_list = load_data( test_path, \"json\")           # 754\n",
    "train_list = load_data( train_path, \"json\")         # 3017\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Server'''\n",
    "kwargs = {}\n",
    "kwargs[\"local_or_remote\"] = \"local\"\n",
    "kwargs[\"server_or_reader\"] = \"server\"\n",
    "kwargs[\"model_name\"] = \"Mistral-7B-Instruct-v0.2\"\n",
    "kwargs[\"gpu_list\"] = \"0\"\n",
    "kwargs[\"local_engine\"] = \"vllm\"\n",
    "inferencer = Inferencer( kwargs )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提示词指令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_instruction = \"\"\"According to the live text, please count the number of: 1.goals, 2. shots, 3.fouls, 4.yellow cards, 5.red cards, 6.corner kicks, 7.free kicks, and 8.offsides for each team. Note that goals and saved attempts and blocked attempts and missed attempts are considered shots. Handball and dangerous play are also considered foul. The second yellow card is also considered a red card. Penalty is also considered as free kicks.\"\"\"\n",
    "\n",
    "stage_1_instruction = \"\"\"{INSTRUCTION}\n",
    "Please extract all the relevant event from the following passage, output them in (player name, team name, event) or (team name, event) format. Constrain the event names to only the following options: 1.goals, 2.shots, 3.fouls, 4.yellow cards, 5.red cards, 6.corner kicks, 7.free kicks, and 8.offsides:\n",
    "{Text}\"\"\"\n",
    "stage_2_DE_instruction = \"\"\"{INSTRUCTION}\n",
    "Please count all the information required and integrate these tuples:\n",
    "{Text}\"\"\"\n",
    "\n",
    "stage_2_CG_instruction = \"\"\"{INSTRUCTION}\n",
    "Please develop a Python code to consolidate these tuples as specified:\n",
    "{Text}\"\"\"\n",
    "stage_3_instruction = \"\"\"{INSTRUCTION}\n",
    "Let’s do the following things: \n",
    "1. Extract all the relevant events from the following passage in (player name, team name, event) or (team name, event) format. \n",
    "2. Integrate these tuples. \n",
    "3. Output a table with 2 rows in CSV format.\n",
    "{Text}\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取第一轮输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sample_text = 'Here are the extracted events in the format of (player name, team name, event) or (team name, event):\\n\\n1. (Player27, Away Team, shot)\\n2. (Player27, Away Team, shot)\\n3. (Away Team, corner kick)\\n4. (Away Team, offside)\\n5. (Away Team, corner kick)\\n6. (Player29, Away Team, shot)\\n7. (Player28, Away Team, free kick)\\n8. (Player20, Away Team, foul)\\n9. (Player7, Home Team, shot)\\n10. (Player11,'\\nresults = extract_pairs_and_triples(sample_text)\\nprint(results)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "# 从字符串中抽取三元组和二元组\n",
    "def unlegal_filter( tup: tuple):\n",
    "    flag = 0\n",
    "    ban_list = [\"team name\", \"Team name\",]\n",
    "    for item in ban_list:\n",
    "        if item in tup:\n",
    "            flag = 1\n",
    "            break\n",
    "    if \"Player \" in tup[0]:\n",
    "        flag = 1\n",
    "    if flag == 0:\n",
    "        return tup\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def extract_pairs_and_triples(text: str) -> List[Tuple[str, ...]]:\n",
    "    \"\"\"\n",
    "    Extract all pairs in the format (xxx, xxx) and triples in the format (xxx, xxx, xxx)\n",
    "    where xxx consists of 1-2 words.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input string containing the pairs and triples.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, ...]]: List of extracted pairs and triples.\n",
    "    \"\"\"\n",
    "    # Regular expressions to match pairs and triples\n",
    "    triple_pattern = re.compile(r\"\\((\\b\\w+(?: \\w+)?), (\\b\\w+(?: \\w+)?), (\\b\\w+(?: \\w+)?)\\)\")\n",
    "    pair_pattern = re.compile(r\"\\((\\b\\w+(?: \\w+)?), (\\b\\w+(?: \\w+)?)\\)\")\n",
    "    trip_matches = triple_pattern.findall(text)\n",
    "    tuple_matches = pair_pattern.findall(text)\n",
    "\n",
    "    ret = []\n",
    "    for matches in [trip_matches, tuple_matches]:\n",
    "        for match in matches:\n",
    "            filt = unlegal_filter( match )\n",
    "            if filt != None:\n",
    "                ret.append( match )\n",
    "    return ret\n",
    "\n",
    "# Example usage\n",
    "'''sample_text = 'Here are the extracted events in the format of (player name, team name, event) or (team name, event):\\n\\n1. (Player27, Away Team, shot)\\n2. (Player27, Away Team, shot)\\n3. (Away Team, corner kick)\\n4. (Away Team, offside)\\n5. (Away Team, corner kick)\\n6. (Player29, Away Team, shot)\\n7. (Player28, Away Team, free kick)\\n8. (Player20, Away Team, foul)\\n9. (Player7, Home Team, shot)\\n10. (Player11,'\n",
    "results = extract_pairs_and_triples(sample_text)\n",
    "print(results)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1_path = os.path.join( _ROOT_PATH, \"prompt_1_list.pickle\")\n",
    "prompt_1_list = []\n",
    "for i in range( len(test_list) ):\n",
    "    prompt_1 = stage_1_instruction.format( INSTRUCTION = general_instruction,  Text = test_list[i][\"text\"])\n",
    "    prompt_1_list.append( [prompt_1 ])\n",
    "save_data( prompt_1_list, prompt_1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enginevllm exists, run with vllm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 12-09 12:44:08 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-09 12:44:08 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "WARNING 12-09 12:44:08 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-09 12:44:08 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "WARNING 12-09 12:44:08 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-09 12:44:08 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "WARNING 12-09 12:44:08 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-09 12:44:08 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "WARNING 12-09 12:44:08 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-09 12:44:08 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "INFO 12-09 12:44:08 selector.py:16] Using FlashAttention backend.\n",
      "INFO 12-09 12:44:08 selector.py:16] Using FlashAttention backend.\n",
      "INFO 12-09 12:44:08 selector.py:16] Using FlashAttention backend.\n",
      "INFO 12-09 12:44:08 selector.py:16] Using FlashAttention backend.\n",
      "INFO 12-09 12:44:08 selector.py:16] Using FlashAttention backend.\n",
      "INFO 12-09 12:44:28 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 12-09 12:44:28 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 12-09 12:44:28 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 12-09 12:44:28 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 12-09 12:44:28 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 12-09 12:44:30 gpu_executor.py:94] # GPU blocks: 953, # CPU blocks: 2048\n",
      "INFO 12-09 12:44:30 gpu_executor.py:94] # GPU blocks: 953, # CPU blocks: 2048\n",
      "INFO 12-09 12:44:30 gpu_executor.py:94] # GPU blocks: 953, # CPU blocks: 2048\n",
      "INFO 12-09 12:44:30 gpu_executor.py:94] # GPU blocks: 953, # CPU blocks: 2048\n",
      "INFO 12-09 12:44:30 gpu_executor.py:94] # GPU blocks: 953, # CPU blocks: 2048\n",
      "INFO 12-09 12:44:32 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-09 12:44:32 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-09 12:44:32 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-09 12:44:32 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-09 12:44:32 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-09 12:44:32 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-09 12:44:32 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-09 12:44:32 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-09 12:44:32 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-09 12:44:32 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-09 12:44:38 model_runner.py:867] Graph capturing finished in 7 secs.\n",
      "INFO 12-09 12:44:38 model_runner.py:867] Graph capturing finished in 7 secs.\n",
      "No.3 LLM Inderence start!\n",
      "No.2 LLM Inderence start!\n",
      "INFO 12-09 12:44:38 model_runner.py:867] Graph capturing finished in 6 secs.\n",
      "No.5 LLM Inderence start!\n",
      "INFO 12-09 12:44:38 model_runner.py:867] Graph capturing finished in 7 secs.\n",
      "No.1 LLM Inderence start!\n",
      "第1部分：:   0%|          | 0/150 [00:00<?, ?it/s]INFO 12-09 12:44:39 model_runner.py:867] Graph capturing finished in 7 secs.\n",
      "No.0 LLM Inderence start!\n",
      "第2部分：: 100%|██████████| 150/150 [1:49:14<00:00, 43.70s/it]   \n",
      "第3部分：: 100%|██████████| 150/150 [1:53:30<00:00, 45.40s/it]it]\n",
      "第5部分：: 100%|██████████| 154/154 [2:08:53<00:00, 50.22s/it]   \n",
      "第0部分：: 100%|██████████| 150/150 [2:14:38<00:00, 53.86s/it]   \n",
      "第1部分：: 100%|██████████| 150/150 [2:29:41<00:00, 59.88s/it]\n",
      "Model inference finished！\n"
     ]
    }
   ],
   "source": [
    "kwargs = {}\n",
    "prompt_list_from_path = prompt_1_path\n",
    "kwargs[\"local_or_remote\"] = \"local\"\n",
    "kwargs[\"server_or_reader\"] = \"reader\"\n",
    "kwargs[\"model_name\"] = \"Mistral-7B-Instruct-v0.2\"\n",
    "kwargs[\"gpu_list\"] = \"0,1,2,3,5\"\n",
    "kwargs[\"local_engine\"] = \"vllm\"\n",
    "if prompt_list_from_path != None:\n",
    "    kwargs[\"prompt_list_from_path\"] = prompt_list_from_path\n",
    "    kwargs[\"predict_list_to_path\"] = prompt_list_from_path.replace( \"prompt_1_list.pickle\", \"predict_1_list.pickle\")\n",
    "    kwargs[\"sample_little\"] = None\n",
    "inferencer = Inferencer( kwargs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过滤输出\n",
    "predict_1_list = load_data( os.path.join(_ROOT_PATH, \"predict_1_list.pickle\"), \"pickle\")\n",
    "\n",
    "tuples_list = []\n",
    "\n",
    "points_dict = {\n",
    "    'shot': [ 'shot', \"missed\", \"header\", \"hits the bar\", \"goes high\", \"goal\", \"blocked\", \"saved\"], \n",
    "    'foul':  [ 'foul', \"dangerous play\", \"handball\"], \n",
    "    'yellow card':  ['yellow card'], \n",
    "    'red card': [ \"red card\", \"sent off\"], \n",
    "    'corner kick' : [ \"corner \"], \n",
    "    'free kick': [ \"free \", \"penalty\"], \n",
    "    'offside':  [ 'offside' ],\n",
    "}\n",
    "\n",
    "for i in range( len(predict_1_list) ):\n",
    "    tuples = extract_pairs_and_triples(predict_1_list[i][0])\n",
    "    temp = []\n",
    "    for _tuple in tuples:\n",
    "        # 遍历每个元组\n",
    "        flag = 0\n",
    "        for item in _tuple:\n",
    "            # 遍历元组中每个项\n",
    "            if \"home \" in item.lower() or \"away \" in item.lower():\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            continue\n",
    "        else:\n",
    "            _field = _tuple[-1]\n",
    "            for key in points_dict.keys():\n",
    "                if _field.lower() in key:\n",
    "                    flag = 2\n",
    "            if flag == 2:\n",
    "                temp.append( _tuple )\n",
    "    \n",
    "    tuples_list.append( temp )\n",
    "\n",
    "save_data( tuples_list, os.path.join(_ROOT_PATH, \"predict_1_filter_list.pickle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取第二轮输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples_list = load_data( os.path.join(_ROOT_PATH, \"predict_1_filter_list.pickle\"), \"pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2_path = os.path.join(_ROOT_PATH, \"prompt_2_list.pickle\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_to_orignal = []\n",
    "valid_list = []\n",
    "for i in range( len(tuples_list) ):\n",
    "    tuples = tuples_list[i]\n",
    "    if len(tuples)>0:\n",
    "        prompt_2 = stage_2_CG_instruction.format( INSTRUCTION = general_instruction,  Text = f\"{tuples}\" )\n",
    "        valid_list.append( [prompt_2] )\n",
    "        valid_to_orignal.append(i )\n",
    "\n",
    "save_data( valid_list, prompt_2_path )\n",
    "save_data( valid_to_orignal, os.path.join(_ROOT_PATH, \"prompt_2_valid_to_orignal.pickle\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_list = load_data( prompt_2_path, \"pickle\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enginevllm exists, run with vllm\n",
      "WARNING 12-10 01:55:28 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-10 01:55:28 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "WARNING 12-10 01:55:28 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-10 01:55:28 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "WARNING 12-10 01:55:28 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-10 01:55:28 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "WARNING 12-10 01:55:28 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-10 01:55:28 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "WARNING 12-10 01:55:28 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-10 01:55:28 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "WARNING 12-10 01:55:28 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-10 01:55:28 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "INFO 12-10 01:55:28 selector.py:16] Using FlashAttention backend.\n",
      "INFO 12-10 01:55:29 selector.py:16] Using FlashAttention backend.\n",
      "INFO 12-10 01:55:29 selector.py:16] Using FlashAttention backend.\n",
      "INFO 12-10 01:55:29 selector.py:16] Using FlashAttention backend.\n",
      "INFO 12-10 01:55:29 selector.py:16] Using FlashAttention backend.\n",
      "INFO 12-10 01:55:29 selector.py:16] Using FlashAttention backend.\n",
      "INFO 12-10 01:55:50 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 12-10 01:55:50 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 12-10 01:55:50 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 12-10 01:55:51 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 12-10 01:55:51 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 12-10 01:55:51 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 12-10 01:55:52 gpu_executor.py:94] # GPU blocks: 3379, # CPU blocks: 2048\n",
      "INFO 12-10 01:55:52 gpu_executor.py:94] # GPU blocks: 3379, # CPU blocks: 2048\n",
      "INFO 12-10 01:55:52 gpu_executor.py:94] # GPU blocks: 3379, # CPU blocks: 2048\n",
      "INFO 12-10 01:55:52 gpu_executor.py:94] # GPU blocks: 3379, # CPU blocks: 2048\n",
      "INFO 12-10 01:55:53 gpu_executor.py:94] # GPU blocks: 3379, # CPU blocks: 2048\n",
      "INFO 12-10 01:55:53 gpu_executor.py:94] # GPU blocks: 3379, # CPU blocks: 2048\n",
      "INFO 12-10 01:55:54 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-10 01:55:54 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-10 01:55:54 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-10 01:55:54 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-10 01:55:54 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-10 01:55:54 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-10 01:55:54 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-10 01:55:54 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-10 01:55:54 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-10 01:55:54 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-10 01:55:54 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-10 01:55:54 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-10 01:56:00 model_runner.py:867] Graph capturing finished in 6 secs.\n",
      "No.2 LLM Inderence start!\n",
      "第2部分：:   0%|          | 0/26 [00:00<?, ?it/s]INFO 12-10 01:56:00 model_runner.py:867] Graph capturing finished in 6 secs.\n",
      "No.1 LLM Inderence start!\n",
      "第1部分：:   0%|          | 0/26 [00:00<?, ?it/s]INFO 12-10 01:56:01 model_runner.py:867] Graph capturing finished in 6 secs.\n",
      "No.0 LLM Inderence start!\n",
      "INFO 12-10 01:56:01 model_runner.py:867] Graph capturing finished in 6 secs.\n",
      "第0部分：:   0%|          | 0/26 [00:00<?, ?it/s]No.5 LLM Inderence start!\n",
      "第5部分：:   0%|          | 0/31 [00:00<?, ?it/s]INFO 12-10 01:56:01 model_runner.py:867] Graph capturing finished in 6 secs.\n",
      "No.4 LLM Inderence start!\n",
      "INFO 12-10 01:56:01 model_runner.py:867] Graph capturing finished in 7 secs.\n",
      "No.3 LLM Inderence start!\n",
      "第2部分：: 100%|██████████| 26/26 [1:53:27<00:00, 261.82s/it]  \n",
      "第1部分：: 100%|██████████| 26/26 [2:11:30<00:00, 303.48s/it]t]\n",
      "第4部分：: 100%|██████████| 26/26 [2:20:16<00:00, 323.71s/it]  \n",
      "第0部分：: 100%|██████████| 26/26 [2:47:45<00:00, 387.13s/it]t]\n",
      "第3部分：: 100%|██████████| 26/26 [3:05:21<00:00, 427.76s/it]  \n",
      "第5部分：: 100%|██████████| 31/31 [3:23:09<00:00, 393.20s/it]\n",
      "Model inference finished！\n"
     ]
    }
   ],
   "source": [
    "kwargs = {}\n",
    "prompt_list_from_path = prompt_2_path  # prompt_2_merge_path\n",
    "kwargs[\"local_or_remote\"] = \"local\"\n",
    "kwargs[\"server_or_reader\"] = \"reader\"\n",
    "kwargs[\"model_name\"] = \"Mistral-7B-Instruct-v0.2\"\n",
    "kwargs[\"gpu_list\"] = \"0,1,2,3,4,5\"\n",
    "kwargs[\"local_engine\"] = \"vllm\"\n",
    "if prompt_list_from_path != None:\n",
    "    kwargs[\"prompt_list_from_path\"] = prompt_list_from_path\n",
    "    kwargs[\"predict_list_to_path\"] = prompt_list_from_path.replace( \"prompt_2_list.pickle\", \"predict_2_list.pickle\")\n",
    "    kwargs[\"sample_little\"] = None\n",
    "inferencer = Inferencer( kwargs )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取第三轮输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_2_list = load_data( os.path.join(_ROOT_PATH, \"predict_2_list.pickle\"), \"pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Failed\n",
      "1 Failed\n",
      "{'goals': 0, 'shots': 0, 'fouls': 11, 'yellow_cards': 3, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 2}\n",
      "{'goals': 0, 'shots': 0, 'fouls': 7, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 1}\n",
      "{'goals': 0, 'shots': 0, 'fouls': 6, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 2}\n",
      "{'goals': 0, 'shots': 1, 'fouls': 4, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 1, 'offsides': 1}\n",
      "4 Failed\n",
      "5 Failed\n",
      "6 Failed\n",
      "7 Failed\n",
      "8 Failed\n",
      "9 Failed\n",
      "10 Failed\n",
      "11 Failed\n",
      "{'goals': 2, 'shots': 15, 'fouls': 11, 'yellow_cards': 1, 'red_cards': 0, 'corner_kicks': 6, 'free_kicks': 11}\n",
      "{'goals': 0, 'shots': 15, 'fouls': 11, 'yellow_cards': 2, 'red_cards': 1, 'corner_kicks': 0, 'free_kicks': 11}\n",
      "13 Failed\n",
      "14 Failed\n",
      "15 Failed\n",
      "16 Failed\n",
      "17 Failed\n",
      "18 Failed\n",
      "19 Failed\n",
      "{'Away': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0}, 'Home': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0}, 'free': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0}, 'corner': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0}}\n",
      "{'Goals': 0, 'Shots': 0, 'Fouls': 2, 'Yellow Cards': 1, 'Red Cards': 1, 'Corner_Kicks': 0, 'Offsides': 1}\n",
      "{'Goals': 0, 'Shots': 0, 'Fouls': 8, 'Yellow Cards': 0, 'Red Cards': 4, 'Corner_Kicks': 2, 'Offsides': 0}\n",
      "22 Failed\n",
      "23 Failed\n",
      "24 Failed\n",
      "25 Failed\n",
      "26 Failed\n",
      "{'Home Team': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}, 'Away Team': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}}\n",
      "28 Failed\n",
      "Home Team Stats:\n",
      "{'goals': 0, 'shots': 13, 'fouls': 14, 'yellow_cards': 8, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}\n",
      "Away Team Stats:\n",
      "{'goals': 0, 'shots': 9, 'fouls': 13, 'yellow_cards': 6, 'red_cards': 1, 'corner_kicks': 0, 'offsides': 0}\n",
      "30 Failed\n",
      "Away Team Stats:\n",
      "Goals: 6\n",
      "Shots: 7\n",
      "Fouls: 7\n",
      "Yellow Cards: 2\n",
      "Red Cards: 5\n",
      "Corner Kicks: 2\n",
      "Free Kicks: 0\n",
      "Offsides: 0\n",
      "\n",
      "Home Team Stats:\n",
      "Goals: 1\n",
      "Shots: 6\n",
      "Fouls: 6\n",
      "Yellow Cards: 2\n",
      "Red Cards: 4\n",
      "Corner Kicks: 3\n",
      "Free Kicks: 0\n",
      "Offsides: 0\n",
      "32 Failed\n",
      "33 Failed\n",
      "34 Failed\n",
      "35 Failed\n",
      "36 Failed\n",
      "37 Failed\n",
      "38 Failed\n",
      "39 Failed\n",
      "Away Team Stats:\n",
      "{'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 0}\n",
      "Home Team Stats:\n",
      "{'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 0}\n",
      "{'goals': 0, 'shots': 1, 'fouls': 9, 'yellow_cards': 1, 'red_cards': 1, 'corner_kicks': 0, 'free_kicks': 4, 'offsides': 2}\n",
      "{'goals': 0, 'shots': 5, 'fouls': 3, 'yellow_cards': 3, 'red_cards': 1, 'corner_kicks': 0, 'free_kicks': 9, 'offsides': 0}\n",
      "{'goals': 0, 'shots': 28, 'fouls': 13, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}\n",
      "{'goals': 0, 'shots': 3, 'fouls': 11, 'yellow_cards': 4, 'red_cards': 3, 'corner_kicks': 0, 'offsides': 2}\n",
      "43 Failed\n",
      "44 Failed\n",
      "45 Failed\n",
      "46 Failed\n",
      "47 Failed\n",
      "{'Goals': 0, 'Shots': 0, 'Fouls': 5, 'Yellow cards': 0, 'Red cards': 0, 'Corner_kicks': 3, 'Free_kicks': 7, 'Offsides': 0}\n",
      "{'Goals': 0, 'Shots': 2, 'Fouls': 9, 'Yellow cards': 2, 'Red cards': 0, 'Corner_kicks': 0, 'Free_kicks': 6, 'Offsides': 2}\n",
      "49 Failed\n",
      "50 Failed\n",
      "{'goals': 0, 'shots': 7, 'fouls': 9, 'yellow_cards': 2, 'red_cards': 7, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 0}\n",
      "{'goals': 0, 'shots': 4, 'fouls': 3, 'yellow_cards': 2, 'red_cards': 1, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 1}\n",
      "52 Failed\n",
      "53 Failed\n",
      "Home Team Stats:\n",
      "{'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}\n",
      "Away Team Stats:\n",
      "{'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}\n",
      "55 Failed\n",
      "Home Team Stats:\n",
      "Goals: 0\n",
      "Shots: 0\n",
      "Fouls: 7\n",
      "Yellow Cards: 1\n",
      "Red Cards: 0\n",
      "Corner Kicks: 0\n",
      "Free Kicks: 3\n",
      "Offsides: 4\n",
      "\n",
      "Away Team Stats:\n",
      "Goals: 0\n",
      "Shots: 0\n",
      "Fouls: 5\n",
      "Yellow Cards: 5\n",
      "Red Cards: 4\n",
      "Corner Kicks: 0\n",
      "Free Kicks: 7\n",
      "Offsides: 2\n",
      "57 Failed\n",
      "58 Failed\n",
      "Home Team Stats: Goals=0, Shots=2, Fouls=2, Yellow Cards=1, Red Cards=0, Corner Kicks=0, Free Kicks=2, Offsides=2\n",
      "Away Team Stats: Goals=0, Shots=11, Fouls=6, Yellow Cards=1, Red Cards=0, Corner Kicks=0, Free Kicks=2, Offsides=2\n",
      "Home Team Stats:\n",
      "Goals: 0\n",
      "Shots: 6\n",
      "Fouls: 5\n",
      "Yellow Cards: 1\n",
      "Red Cards: 0\n",
      "Corner Kicks: 0\n",
      "Offsides: 5\n",
      "\n",
      "Away Team Stats:\n",
      "Goals: 0\n",
      "Shots: 11\n",
      "Fouls: 3\n",
      "Yellow Cards: 1\n",
      "Red Cards: 0\n",
      "Corner Kicks: 0\n",
      "Offsides: 1\n",
      "61 Failed\n",
      "Away Team Stats:\n",
      "{'goals': 0, 'shots': 0, 'fouls': 6, 'yellow_cards': 2, 'red_cards': 4, 'corner_kicks': 0, 'free_kicks': 5, 'offsides': 3}\n",
      "Home Team Stats:\n",
      "{'goals': 0, 'shots': 0, 'fouls': 2, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 0}\n",
      "Home Team:\n",
      "Goals: 0\n",
      "Shots: 7\n",
      "Fouls: 6\n",
      "Yellow Cards: 2\n",
      "Red Cards: 4\n",
      "Corner Kicks: 0\n",
      "Free Kicks: 4\n",
      "Offsides: 0\n",
      "\n",
      "Away Team:\n",
      "Goals: 0\n",
      "Shots: 0\n",
      "Fouls: 4\n",
      "Yellow Cards: 2\n",
      "Red Cards: 2\n",
      "Corner Kicks: 0\n",
      "Free Kicks: 1\n",
      "Offsides: 0\n",
      "64 Failed\n",
      "65 Failed\n",
      "66 Failed\n",
      "67 Failed\n",
      "{'Home Team': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}, 'Away Team': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}}\n",
      "69 Failed\n",
      "70 Failed\n",
      "71 Failed\n",
      "72 Failed\n",
      "73 Failed\n",
      "74 Failed\n",
      "75 Failed\n",
      "76 Failed\n",
      "77 Failed\n",
      "78 Failed\n",
      "79 Failed\n",
      "80 Failed\n",
      "81 Failed\n",
      "82 Failed\n",
      "83 Failed\n",
      "84 Failed\n",
      "85 Failed\n",
      "86 Failed\n",
      "87 Failed\n",
      "88 Failed\n",
      "89 Failed\n",
      "90 Failed\n",
      "91 Failed\n",
      "Home Team Stats:\n",
      "{'Goals': 0, 'Shots': 8, 'Fouls': 3, 'Yellow Cards': 1, 'Red Cards': 0, 'Corner Kicks': 0, 'Offsides': 1}\n",
      "Away Team Stats:\n",
      "{'Goals': 0, 'Shots': 0, 'Fouls': 9, 'Yellow Cards': 0, 'Red Cards': 0, 'Corner Kicks': 0, 'Offsides': 2}\n",
      "93 Failed\n",
      "94 Failed\n",
      "95 Failed\n",
      "96 Failed\n",
      "97 Failed\n",
      "98 Failed\n",
      "99 Failed\n",
      "100 Failed\n",
      "101 Failed\n",
      "102 Failed\n",
      "103 Failed\n",
      "104 Failed\n",
      "Home Team Stats:\n",
      "{'Goals': 0, 'Shots': 4, 'Fouls': 7, 'Yellow Cards': 1, 'Red Cards': 0, 'Corner Kicks': 1, 'Offsides': 2}\n",
      "Away Team Stats:\n",
      "{'Goals': 0, 'Shots': 8, 'Fouls': 2, 'Yellow Cards': 1, 'Red Cards': 0, 'Corner Kicks': 2, 'Offsides': 0}\n",
      "106 Failed\n",
      "107 Failed\n",
      "108 Failed\n",
      "109 Failed\n",
      "110 Failed\n",
      "{'goals': 0, 'shots': 0, 'fouls': 7, 'yellow_cards': 1, 'red_cards': 0, 'corner_kicks': 1, 'offsides': 0}\n",
      "{'goals': 0, 'shots': 0, 'fouls': 7, 'yellow_cards': 3, 'red_cards': 1, 'corner_kicks': 3, 'offsides': 4}\n",
      "112 Failed\n",
      "113 Failed\n",
      "{'goals': 0, 'shots': 0, 'fouls': 5, 'yellow_cards': 2, 'red_cards': 3, 'corner_kicks': 0, 'free_kicks': 6, 'offsides': 1}\n",
      "{'goals': 0, 'shots': 3, 'fouls': 2, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 5, 'offsides': 1}\n",
      "115 Failed\n",
      "116 Failed\n",
      "117 Failed\n",
      "118 Failed\n",
      "119 Failed\n",
      "120 Failed\n",
      "121 Failed\n",
      "122 Failed\n",
      "123 Failed\n",
      "124 Failed\n",
      "125 Failed\n",
      "126 Failed\n",
      "127 Failed\n",
      "{'goals': 0, 'shots': 3, 'fouls': 10, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 3}\n",
      "{'goals': 0, 'shots': 8, 'fouls': 4, 'yellow_cards': 4, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 8}\n",
      "129 Failed\n",
      "130 Failed\n",
      "131 Failed\n",
      "132 Failed\n",
      "133 Failed\n",
      "134 Failed\n",
      "{'goals': 0, 'shots': 4, 'fouls': 3, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0}\n",
      "{'goals': 0, 'shots': 3, 'fouls': 5, 'yellow_cards': 1, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 2}\n",
      "136 Failed\n",
      "137 Failed\n",
      "{'goals': 0, 'shots': 0, 'fouls': 8, 'yellow_cards': 1, 'red_cards': 0, 'corner_kicks': 3, 'offsides': 1}\n",
      "{'goals': 0, 'shots': 0, 'fouls': 3, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 3, 'offsides': 2}\n",
      "Home Team Stats:\n",
      "Goals: 0\n",
      "Shots: 0\n",
      "Fouls: 0\n",
      "Yellow Cards: 0\n",
      "Red Cards: 0\n",
      "Corner Kicks: 0\n",
      "Free Kicks: 0\n",
      "Offsides: 0\n",
      "Events: {}\n",
      "\n",
      "Away Team Stats:\n",
      "Goals: 0\n",
      "Shots: 0\n",
      "Fouls: 0\n",
      "Yellow Cards: 0\n",
      "Red Cards: 0\n",
      "Corner Kicks: 0\n",
      "Free Kicks: 0\n",
      "Offsides: 0\n",
      "Events: {'goal! home team 1-0 away team. 12 mins': ['Goal! Home Team 1-0 Away Team. 12 mins: GOAL_HOME_TEAM'], 'shot saved! away team. 15 mins': ['Shot saved! Away Team. 15 mins: SHOT_SAVED_AWAY_TEAM'], 'foul by home team. 18 mins': ['Foul by Home Team. 18 mins: FOUL_HOME_TEAM'], 'yellow card for home team player. 20 mins': ['Yellow Card for Home Team player. 20 mins: YELLOW_CARD_HOME_TEAM'], 'penalty for away team. 25 mins': ['Penalty for Away Team. 25 mins: PENALTY_AWAY_TEAM'], 'foul by away team. 30 mins': ['Foul by Away Team. 30 mins: FOUL_AWAY_TEAM'], 'offside by home team player. 35 mins': ['Offside by Home Team player. 35 mins: OFFSIDE_HOME_TEAM'], 'shot on target! away team. 40 mins': ['Shot on target! Away Team. 40 mins: SHOT_ON_TARGET_AWAY_TEAM'], 'foul by home team. 45 mins': ['Foul by Home Team. 45 mins: FOUL_HOME_TEAM'], 'yellow card for away team player. 45+1 mins': ['Yellow Card for Away Team player. 45+1 mins: YELLOW_CARD_AWAY_TEAM'], 'red card for home team player. 45+3 mins': ['Red Card for Home Team player. 45+3 mins: RED_CARD_HOME_TEAM'], 'corner kick for home team. 48 mins': ['Corner kick for Home Team. 48 mins: CORNER_KICK_HOME_TEAM'], 'corner kick for away team. 50 mins': ['Corner kick for Away Team. 50 mins: CORNER_KICK_AWAY_TEAM'], 'corner kick for home team. 55 mins': ['Corner kick for Home Team. 55 mins: CORNER_KICK_HOME_TEAM'], 'free kick for away team. 60 mins': ['Free kick for Away Team. 60 mins: FREE_KICK_AWAY_TEAM'], 'shot blocked! home team. 65 mins': ['Shot blocked! Home Team. 65 mins: SHOT_BLOCKED_HOME_TEAM'], 'foul by away team. 70 mins': ['Foul by Away Team. 70 mins: FOUL_AWAY_TEAM'], 'goal! away team 1-1 home team. 75 mins': ['Goal! Away Team 1-1 Home Team. 75 mins: GOAL_AWAY_TEAM'], 'shot missed! home team. 80 mins': ['Shot missed! Home Team. 80 mins: SHOT_MISSED_HOME_TEAM'], 'handball by away team player. 85 mins': ['Handball by Away Team player. 85 mins: HANDBALL_AWAY_TEAM'], 'foul by home team. 90 mins': ['Foul by Home Team. 90 mins: FOUL_HOME_TEAM']}\n",
      "{'Home Team': {'Goals': 4, 'Shots': 17, 'Fouls': 16, 'Yellow Cards': 2, 'Red Cards': 5, 'Corner Kicks': 4, 'Free Kicks': 3, 'Offsides': 0}, 'Away Team': {'Goals': 3, 'Shots': 18, 'Fouls': 19, 'Yellow Cards': 2, 'Red Cards': 7, 'Corner Kicks': 5, 'Free Kicks': 5, 'Offsides': 2}}\n",
      "141 Failed\n",
      "142 Failed\n",
      "{'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}\n",
      "{'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}\n",
      "144 Failed\n",
      "145 Failed\n",
      "146 Failed\n",
      "147 Failed\n",
      "148 Failed\n",
      "{'goals': 0, 'shots': 7, 'fouls': 3, 'yellow_cards': 2, 'red_cards': 1, 'corner_kicks': 4, 'free_kicks': 14}\n",
      "{'goals': 0, 'shots': 0, 'fouls': 3, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 1, 'free_kicks': 9}\n",
      "150 Failed\n",
      "151 Failed\n",
      "152 Failed\n",
      "153 Failed\n",
      "154 Failed\n",
      "155 Failed\n",
      "156 Failed\n",
      "157 Failed\n",
      "158 Failed\n",
      "{'Home Team': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 7, 'free_kicks': 13, 'offside': 1}, 'Away Team': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 1, 'red_cards': 0, 'corner_kicks': 2, 'free_kicks': 11, 'offside': 0}}\n",
      "160 Failed\n"
     ]
    }
   ],
   "source": [
    "executable_list = []\n",
    "\n",
    "for i in range( len(predict_2_list) ):\n",
    "    text = predict_2_list[i][0].split(\"```python\")[1].strip()\n",
    "    text = text.split(\"```\")[0].strip()\n",
    "    try:\n",
    "        exec( text )\n",
    "        executable_list.append( True )\n",
    "    except:\n",
    "        executable_list.append( False )\n",
    "        print( f\"{i} Failed\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "excuta = {\n",
    "    2: {\n",
    "        \"home team\": {'goals': 0, 'shots': 0, 'fouls': 11, 'yellow_cards': 3, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 2},\n",
    "        \"away team\": {'goals': 0, 'shots': 0, 'fouls': 7, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 1}\n",
    "    },\n",
    "    3: {\n",
    "        \"home team\": {'goals': 0, 'shots': 0, 'fouls': 6, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 2},\n",
    "        \"away team\": {'goals': 0, 'shots': 1, 'fouls': 4, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 1, 'offsides': 1}\n",
    "    },\n",
    "    12: {\n",
    "        \"home team\": {'goals': 2, 'shots': 15, 'fouls': 11, 'yellow_cards': 1, 'red_cards': 0, 'corner_kicks': 6, 'free_kicks': 11},\n",
    "        \"away team\": {'goals': 0, 'shots': 15, 'fouls': 11, 'yellow_cards': 2, 'red_cards': 1, 'corner_kicks': 0, 'free_kicks': 11}\n",
    "    },\n",
    "    20: {\n",
    "        'Away': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0}, \n",
    "        'Home': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0}, \n",
    "        'free': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0}, \n",
    "        'corner': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0}\n",
    "    },\n",
    "    21: {\n",
    "        \"home team\": {'Goals': 0, 'Shots': 0, 'Fouls': 2, 'Yellow Cards': 1, 'Red Cards': 1, 'Corner_Kicks': 0, 'Offsides': 1},\n",
    "        \"away team\": {'Goals': 0, 'Shots': 0, 'Fouls': 8, 'Yellow Cards': 0, 'Red Cards': 4, 'Corner_Kicks': 2, 'Offsides': 0}\n",
    "    },\n",
    "    27: {'Home Team': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}, 'Away Team': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}},\n",
    "    29: {\n",
    "        \"home team\": {'goals': 0, 'shots': 13, 'fouls': 14, 'yellow_cards': 8, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0},\n",
    "        \"away team\": {'goals': 0, 'shots': 9, 'fouls': 13, 'yellow_cards': 6, 'red_cards': 1, 'corner_kicks': 0, 'offsides': 0}\n",
    "    },\n",
    "    31: {\n",
    "        \"home team\": \"\"\"Goals: 1\n",
    "                    Shots: 6\n",
    "                    Fouls: 6\n",
    "                    Yellow Cards: 2\n",
    "                    Red Cards: 4\n",
    "                    Corner Kicks: 3\n",
    "                    Free Kicks: 0\n",
    "                    Offsides: 0\"\"\",\n",
    "        \"away team\": \"\"\"\"Goals: 6\n",
    "                    Shots: 7\n",
    "                    Fouls: 7\n",
    "                    Yellow Cards: 2\n",
    "                    Red Cards: 5\n",
    "                    Corner Kicks: 2\n",
    "                    Free Kicks: 0\n",
    "                    Offsides: 0\"\"\"\n",
    "    },\n",
    "    40: {\n",
    "        \"home team\": {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 0},\n",
    "        \"away team\": {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 0}\n",
    "    },\n",
    "    41: {\n",
    "        \"home team\": {'goals': 0, 'shots': 1, 'fouls': 9, 'yellow_cards': 1, 'red_cards': 1, 'corner_kicks': 0, 'free_kicks': 4, 'offsides': 2},\n",
    "        \"away team\": {'goals': 0, 'shots': 5, 'fouls': 3, 'yellow_cards': 3, 'red_cards': 1, 'corner_kicks': 0, 'free_kicks': 9, 'offsides': 0}\n",
    "    },\n",
    "    42: {\n",
    "        \"home team\": {'goals': 0, 'shots': 28, 'fouls': 13, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0},\n",
    "        \"away team\": {'goals': 0, 'shots': 3, 'fouls': 11, 'yellow_cards': 4, 'red_cards': 3, 'corner_kicks': 0, 'offsides': 2}\n",
    "    },\n",
    "    48: {\n",
    "        \"home team\": {'Goals': 0, 'Shots': 0, 'Fouls': 5, 'Yellow cards': 0, 'Red cards': 0, 'Corner_kicks': 3, 'Free_kicks': 7, 'Offsides': 0},\n",
    "        \"away team\": {'Goals': 0, 'Shots': 2, 'Fouls': 9, 'Yellow cards': 2, 'Red cards': 0, 'Corner_kicks': 0, 'Free_kicks': 6, 'Offsides': 2}\n",
    "    },\n",
    "    51: {\n",
    "        \"home team\": {'goals': 0, 'shots': 7, 'fouls': 9, 'yellow_cards': 2, 'red_cards': 7, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 0},\n",
    "        \"away team\": {'goals': 0, 'shots': 4, 'fouls': 3, 'yellow_cards': 2, 'red_cards': 1, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 1}\n",
    "    },\n",
    "    54: {\n",
    "        \"home team\": {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0},\n",
    "        \"away team\": {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}\n",
    "    },\n",
    "    56: {\n",
    "        \"home team\": \"\"\"Home Team Stats:\n",
    "                        Goals: 0\n",
    "                        Shots: 0\n",
    "                        Fouls: 7\n",
    "                        Yellow Cards: 1\n",
    "                        Red Cards: 0\n",
    "                        Corner Kicks: 0\n",
    "                        Free Kicks: 3\n",
    "                        Offsides: 4\n",
    "                        \"\"\",\n",
    "        \"away team\": \"\"\"Away Team Stats:\n",
    "                        Goals: 0\n",
    "                        Shots: 0\n",
    "                        Fouls: 5\n",
    "                        Yellow Cards: 5\n",
    "                        Red Cards: 4\n",
    "                        Corner Kicks: 0\n",
    "                        Free Kicks: 7\n",
    "                        Offsides: 2\"\"\"\n",
    "    },\n",
    "    59: {\n",
    "        \"home team\": \"Home Team Stats: Goals=0, Shots=2, Fouls=2, Yellow Cards=1, Red Cards=0, Corner Kicks=0, Free Kicks=2, Offsides=2\",\n",
    "        \"away team\": \"Away Team Stats: Goals=0, Shots=11, Fouls=6, Yellow Cards=1, Red Cards=0, Corner Kicks=0, Free Kicks=2, Offsides=2\"\n",
    "    },\n",
    "    60: {\n",
    "        \"home team\": \"\"\"Home Team Stats:\n",
    "                        Goals: 0\n",
    "                        Shots: 6\n",
    "                        Fouls: 5\n",
    "                        Yellow Cards: 1\n",
    "                        Red Cards: 0\n",
    "                        Corner Kicks: 0\n",
    "                        Offsides: 5\"\"\",\n",
    "        \"away team\": \"\"\"Away Team Stats:\n",
    "                        Goals: 0\n",
    "                        Shots: 11\n",
    "                        Fouls: 3\n",
    "                        Yellow Cards: 1\n",
    "                        Red Cards: 0\n",
    "                        Corner Kicks: 0\n",
    "                        Offsides: 1\"\"\"\n",
    "    },\n",
    "    62: {\n",
    "        \"home team\": {'goals': 0, 'shots': 0, 'fouls': 2, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0, 'offsides': 0},\n",
    "        \"away team\": {'goals': 0, 'shots': 0, 'fouls': 6, 'yellow_cards': 2, 'red_cards': 4, 'corner_kicks': 0, 'free_kicks': 5, 'offsides': 3}\n",
    "    },\n",
    "    63: {\n",
    "        \"home team\": \"\"\"Goals: 0\n",
    "                        Shots: 7\n",
    "                        Fouls: 6\n",
    "                        Yellow Cards: 2\n",
    "                        Red Cards: 4\n",
    "                        Corner Kicks: 0\n",
    "                        Free Kicks: 4\n",
    "                        Offsides: 0\"\"\",\n",
    "        \"away team\": \"\"\"Goals: 0\n",
    "                        Shots: 0\n",
    "                        Fouls: 4\n",
    "                        Yellow Cards: 2\n",
    "                        Red Cards: 2\n",
    "                        Corner Kicks: 0\n",
    "                        Free Kicks: 1\n",
    "                        Offsides: 0\"\"\"\n",
    "    },\n",
    "    68: {'Home Team': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}, 'Away Team': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}},\n",
    "    92: {\n",
    "        \"home team\": {'Goals': 0, 'Shots': 8, 'Fouls': 3, 'Yellow Cards': 1, 'Red Cards': 0, 'Corner Kicks': 0, 'Offsides': 1},\n",
    "        \"away team\": {'Goals': 0, 'Shots': 0, 'Fouls': 9, 'Yellow Cards': 0, 'Red Cards': 0, 'Corner Kicks': 0, 'Offsides': 2}\n",
    "    },\n",
    "    105: {\n",
    "        \"home team\": {'Goals': 0, 'Shots': 4, 'Fouls': 7, 'Yellow Cards': 1, 'Red Cards': 0, 'Corner Kicks': 1, 'Offsides': 2},\n",
    "        \"away team\": {'Goals': 0, 'Shots': 8, 'Fouls': 2, 'Yellow Cards': 1, 'Red Cards': 0, 'Corner Kicks': 2, 'Offsides': 0}\n",
    "    },\n",
    "    111: {\n",
    "        \"home team\": {'goals': 0, 'shots': 0, 'fouls': 7, 'yellow_cards': 1, 'red_cards': 0, 'corner_kicks': 1, 'offsides': 0},\n",
    "        \"away team\": {'goals': 0, 'shots': 0, 'fouls': 7, 'yellow_cards': 3, 'red_cards': 1, 'corner_kicks': 3, 'offsides': 4}\n",
    "    },\n",
    "    114: {\n",
    "        \"home team\": {'goals': 0, 'shots': 0, 'fouls': 5, 'yellow_cards': 2, 'red_cards': 3, 'corner_kicks': 0, 'free_kicks': 6, 'offsides': 1},\n",
    "        \"away team\": {'goals': 0, 'shots': 3, 'fouls': 2, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 5, 'offsides': 1}\n",
    "    },\n",
    "    128: {\n",
    "        \"home team\": {'goals': 0, 'shots': 3, 'fouls': 10, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 3},\n",
    "        \"away team\": {'goals': 0, 'shots': 8, 'fouls': 4, 'yellow_cards': 4, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 8}\n",
    "    },\n",
    "    135: {\n",
    "        \"home team\": {'goals': 0, 'shots': 4, 'fouls': 3, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 0},\n",
    "        \"away team\": {'goals': 0, 'shots': 3, 'fouls': 5, 'yellow_cards': 1, 'red_cards': 0, 'corner_kicks': 0, 'free_kicks': 2}\n",
    "    },\n",
    "    138: {\n",
    "        \"home team\": {'goals': 0, 'shots': 0, 'fouls': 8, 'yellow_cards': 1, 'red_cards': 0, 'corner_kicks': 3, 'offsides': 1},\n",
    "        \"away team\": {'goals': 0, 'shots': 0, 'fouls': 3, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 3, 'offsides': 2}\n",
    "    },\n",
    "    139: {\n",
    "        \"home team\": \"\"\"Goals: 0\n",
    "                        Shots: 0\n",
    "                        Fouls: 0\n",
    "                        Yellow Cards: 0\n",
    "                        Red Cards: 0\n",
    "                        Corner Kicks: 0\n",
    "                        Free Kicks: 0\n",
    "                        Offsides: 0\n",
    "                        Events: {}\"\"\",\n",
    "        \"away team\": \"\"\"Goals: 0\n",
    "                        Shots: 0\n",
    "                        Fouls: 0\n",
    "                        Yellow Cards: 0\n",
    "                        Red Cards: 0\n",
    "                        Corner Kicks: 0\n",
    "                        Free Kicks: 0\n",
    "                        Offsides: 0\n",
    "                        Events: {'goal! home team 1-0 away team. 12 mins': ['Goal! Home Team 1-0 Away Team. 12 mins: GOAL_HOME_TEAM'], 'shot saved! away team. 15 mins': ['Shot saved! Away Team. 15 mins: SHOT_SAVED_AWAY_TEAM'], 'foul by home team. 18 mins': ['Foul by Home Team. 18 mins: FOUL_HOME_TEAM'], 'yellow card for home team player. 20 mins': ['Yellow Card for Home Team player. 20 mins: YELLOW_CARD_HOME_TEAM'], 'penalty for away team. 25 mins': ['Penalty for Away Team. 25 mins: PENALTY_AWAY_TEAM'], 'foul by away team. 30 mins': ['Foul by Away Team. 30 mins: FOUL_AWAY_TEAM'], 'offside by home team player. 35 mins': ['Offside by Home Team player. 35 mins: OFFSIDE_HOME_TEAM'], 'shot on target! away team. 40 mins': ['Shot on target! Away Team. 40 mins: SHOT_ON_TARGET_AWAY_TEAM'], 'foul by home team. 45 mins': ['Foul by Home Team. 45 mins: FOUL_HOME_TEAM'], 'yellow card for away team player. 45+1 mins': ['Yellow Card for Away Team player. 45+1 mins: YELLOW_CARD_AWAY_TEAM'], 'red card for home team player. 45+3 mins': ['Red Card for Home Team player. 45+3 mins: RED_CARD_HOME_TEAM'], 'corner kick for home team. 48 mins': ['Corner kick for Home Team. 48 mins: CORNER_KICK_HOME_TEAM'], 'corner kick for away team. 50 mins': ['Corner kick for Away Team. 50 mins: CORNER_KICK_AWAY_TEAM'], 'corner kick for home team. 55 mins': ['Corner kick for Home Team. 55 mins: CORNER_KICK_HOME_TEAM'], 'free kick for away team. 60 mins': ['Free kick for Away Team. 60 mins: FREE_KICK_AWAY_TEAM'], 'shot blocked! home team. 65 mins': ['Shot blocked! Home Team. 65 mins: SHOT_BLOCKED_HOME_TEAM'], 'foul by away team. 70 mins': ['Foul by Away Team. 70 mins: FOUL_AWAY_TEAM'], 'goal! away team 1-1 home team. 75 mins': ['Goal! Away Team 1-1 Home Team. 75 mins: GOAL_AWAY_TEAM'], 'shot missed! home team. 80 mins': ['Shot missed! Home Team. 80 mins: SHOT_MISSED_HOME_TEAM'], 'handball by away team player. 85 mins': ['Handball by Away Team player. 85 mins: HANDBALL_AWAY_TEAM'], 'foul by home team. 90 mins': ['Foul by Home Team. 90 mins: FOUL_HOME_TEAM']}\"\"\"\n",
    "    },\n",
    "    140: {'Home Team': {'Goals': 4, 'Shots': 17, 'Fouls': 16, 'Yellow Cards': 2, 'Red Cards': 5, 'Corner Kicks': 4, 'Free Kicks': 3, 'Offsides': 0}, 'Away Team': {'Goals': 3, 'Shots': 18, 'Fouls': 19, 'Yellow Cards': 2, 'Red Cards': 7, 'Corner Kicks': 5, 'Free Kicks': 5, 'Offsides': 2}},\n",
    "    143: {\n",
    "        \"home team\": {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0},\n",
    "        \"away team\": {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 0, 'offsides': 0}\n",
    "    },\n",
    "    149: {\n",
    "        \"home team\": {'goals': 0, 'shots': 7, 'fouls': 3, 'yellow_cards': 2, 'red_cards': 1, 'corner_kicks': 4, 'free_kicks': 14},\n",
    "        \"away team\": {'goals': 0, 'shots': 0, 'fouls': 3, 'yellow_cards': 2, 'red_cards': 0, 'corner_kicks': 1, 'free_kicks': 9}\n",
    "    },\n",
    "    159: {'Home Team': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 0, 'red_cards': 0, 'corner_kicks': 7, 'free_kicks': 13, 'offside': 1}, 'Away Team': {'goals': 0, 'shots': 0, 'fouls': 0, 'yellow_cards': 1, 'red_cards': 0, 'corner_kicks': 2, 'free_kicks': 11, 'offside': 0}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_2_3 = []\n",
    "prompt_3_list = []\n",
    "for i in range( len(predict_2_list) ):\n",
    "    if i in excuta:\n",
    "        context = excuta[i]\n",
    "        map_2_3.append( i )\n",
    "        prompt_3 = stage_3_instruction.format( INSTRUCTION = general_instruction,  Text = context )\n",
    "        prompt_3_list.append( [prompt_3] )\n",
    "\n",
    "prompt_3_path = os.path.join(_ROOT_PATH, \"prompt_3_list.pickle\" )\n",
    "save_data( prompt_3_list, prompt_3_path)\n",
    "save_data( map_2_3, prompt_3_path.replace( \"prompt_3_list\", \"prompt_3_map_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enginevllm exists, run with vllm\n",
      "WARNING 12-10 11:27:48 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-10 11:27:48 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "WARNING 12-10 11:27:48 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-10 11:27:48 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/workspace/LLMs/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "INFO 12-10 11:27:49 selector.py:16] Using FlashAttention backend.\n",
      "INFO 12-10 11:27:49 selector.py:16] Using FlashAttention backend.\n",
      "INFO 12-10 11:28:05 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 12-10 11:28:05 model_runner.py:104] Loading model weights took 13.4966 GB\n",
      "INFO 12-10 11:28:06 gpu_executor.py:94] # GPU blocks: 3379, # CPU blocks: 2048\n",
      "INFO 12-10 11:28:07 gpu_executor.py:94] # GPU blocks: 3379, # CPU blocks: 2048\n",
      "INFO 12-10 11:28:08 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-10 11:28:08 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-10 11:28:08 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-10 11:28:08 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-10 11:28:14 model_runner.py:867] Graph capturing finished in 6 secs.\n",
      "No.4 LLM Inderence start!\n",
      "第4部分：:   0%|          | 0/16 [00:00<?, ?it/s]INFO 12-10 11:28:15 model_runner.py:867] Graph capturing finished in 7 secs.\n",
      "No.5 LLM Inderence start!\n",
      "第5部分：: 100%|██████████| 16/16 [35:52<00:00, 134.53s/it] \n",
      "第4部分：: 100%|██████████| 16/16 [1:07:44<00:00, 254.02s/it]\n",
      "Model inference finished！\n"
     ]
    }
   ],
   "source": [
    "kwargs = {}\n",
    "prompt_list_from_path = prompt_3_path  # prompt_2_merge_path\n",
    "kwargs[\"local_or_remote\"] = \"local\"\n",
    "kwargs[\"server_or_reader\"] = \"reader\"\n",
    "kwargs[\"model_name\"] = \"Mistral-7B-Instruct-v0.2\"\n",
    "kwargs[\"gpu_list\"] = \"4,5\"\n",
    "kwargs[\"local_engine\"] = \"vllm\"\n",
    "if prompt_list_from_path != None:\n",
    "    kwargs[\"prompt_list_from_path\"] = prompt_list_from_path\n",
    "    kwargs[\"predict_list_to_path\"] = prompt_list_from_path.replace( \"prompt_3_list.pickle\", \"predict_3_list.pickle\")\n",
    "    kwargs[\"sample_little\"] = None\n",
    "inferencer = Inferencer( kwargs )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
