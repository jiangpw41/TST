{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from wayne_utils import load_data, save_data\n",
    "_ROOT_PATH = \"workspace/projects/TKGT\"\n",
    "from llm_inferencer import Register, Inferencer\n",
    "reg = Register()\n",
    "reg.list_models()\n",
    "# reg.add_local_model( \"CPL_dynamic_tabel_Qwen1.5-7B-Chat-4epoch\", \"workspace/TKGT/test/CPL_dynamic/v1/models/5\")\n",
    "#reg.modify_local_model( \"CPL_dynamic_counter_Chinese-Mistral-7B-Instruct-v0.1-3epoch\", \"workspace/projects/TKGT/test/CPL_dynamic/v1/models/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本地推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPL_dynamic_counter_Chinese-Mistral-7B-Instruct-v0.1-3epoch']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list_counter = [\n",
    "    \"ChatGLM3-6B\",\n",
    "    \"Qwen1.5-7B-Chat\",\n",
    "    \"Baichuan2-7B-Chat\",\n",
    "    \"Chinese-Mistral-7B-Instruct-v0.1\",\n",
    "    \"Qwen2.5-0.5B\",\n",
    "    \"CPL_dynamic_counter_ChatGLM3-6B-3epoch\",\n",
    "    \"CPL_dynamic_counter_Chinese-Mistral-7B-Instruct-v0.1-3epoch\",\n",
    "    \"CPL_dynamic_counter_Qwen1.5-7B-Chat-3epoch\"\n",
    "]\n",
    "\n",
    "model_list_table = [\n",
    "    \"ChatGLM3-6B\",\n",
    "    \"Qwen1.5-7B-Chat\",\n",
    "    \"Baichuan2-7B-Chat\",\n",
    "    \"Chinese-Mistral-7B-Instruct-v0.1\",\n",
    "    \"Qwen2.5-0.5B\",\n",
    "    \"CPL_dynamic_tabel_Qwen1.5-7B-Chat-4epoch\",\n",
    "    \"CPL_dynamic_tabel_ChatGLM3-6B-4epoch\",\n",
    "    \"CPL_dynamic_tabel_Chinese-Mistral-7B-Instruct-v0.1-4epoch\",\n",
    "]\n",
    "scopes = model_list_counter[6:7]\n",
    "scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPL_dynamic_counter_Chinese-Mistral-7B-Instruct-v0.1-3epoch开始！\n",
      "Enginevllm exists, run with vllm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 02-01 20:41:08 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 02-01 20:41:08 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/projects/TKGT/test/CPL_dynamic/v1/models/1', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/projects/TKGT/test/CPL_dynamic/v1/models/1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "WARNING 02-01 20:41:08 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 02-01 20:41:08 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/projects/TKGT/test/CPL_dynamic/v1/models/1', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/projects/TKGT/test/CPL_dynamic/v1/models/1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "WARNING 02-01 20:41:08 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "WARNING 02-01 20:41:08 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "WARNING 02-01 20:41:08 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 02-01 20:41:08 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/projects/TKGT/test/CPL_dynamic/v1/models/1', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/projects/TKGT/test/CPL_dynamic/v1/models/1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "INFO 02-01 20:41:08 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/projects/TKGT/test/CPL_dynamic/v1/models/1', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/projects/TKGT/test/CPL_dynamic/v1/models/1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "INFO 02-01 20:41:08 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/projects/TKGT/test/CPL_dynamic/v1/models/1', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/projects/TKGT/test/CPL_dynamic/v1/models/1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "WARNING 02-01 20:41:08 config.py:748] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 02-01 20:41:08 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='/home/jiangpeiwen2/jiangpeiwen2/projects/TKGT/test/CPL_dynamic/v1/models/1', tokenizer='/home/jiangpeiwen2/jiangpeiwen2/projects/TKGT/test/CPL_dynamic/v1/models/1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=32)\n",
      "INFO 02-01 20:41:09 selector.py:16] Using FlashAttention backend.\n",
      "INFO 02-01 20:41:09 selector.py:16] Using FlashAttention backend.\n",
      "INFO 02-01 20:41:09 selector.py:16] Using FlashAttention backend.\n",
      "INFO 02-01 20:41:09 selector.py:16] Using FlashAttention backend.\n",
      "INFO 02-01 20:41:09 selector.py:16] Using FlashAttention backend.\n",
      "INFO 02-01 20:41:09 selector.py:16] Using FlashAttention backend.\n",
      "INFO 02-01 20:41:19 model_runner.py:104] Loading model weights took 13.9849 GB\n",
      "INFO 02-01 20:41:19 model_runner.py:104] Loading model weights took 13.9849 GB\n",
      "INFO 02-01 20:41:19 model_runner.py:104] Loading model weights took 13.9849 GB\n",
      "INFO 02-01 20:41:19 model_runner.py:104] Loading model weights took 13.9849 GB\n",
      "INFO 02-01 20:41:19 model_runner.py:104] Loading model weights took 13.9849 GB\n",
      "INFO 02-01 20:41:20 model_runner.py:104] Loading model weights took 13.9849 GB\n",
      "INFO 02-01 20:41:20 gpu_executor.py:94] # GPU blocks: 3244, # CPU blocks: 2048\n",
      "INFO 02-01 20:41:20 gpu_executor.py:94] # GPU blocks: 3244, # CPU blocks: 2048\n",
      "INFO 02-01 20:41:20 gpu_executor.py:94] # GPU blocks: 3244, # CPU blocks: 2048\n",
      "INFO 02-01 20:41:20 gpu_executor.py:94] # GPU blocks: 3244, # CPU blocks: 2048\n",
      "INFO 02-01 20:41:21 gpu_executor.py:94] # GPU blocks: 3244, # CPU blocks: 2048\n",
      "INFO 02-01 20:41:21 gpu_executor.py:94] # GPU blocks: 3244, # CPU blocks: 2048\n",
      "INFO 02-01 20:41:22 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 02-01 20:41:22 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 02-01 20:41:22 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 02-01 20:41:22 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 02-01 20:41:22 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 02-01 20:41:22 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 02-01 20:41:22 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 02-01 20:41:22 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 02-01 20:41:23 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 02-01 20:41:23 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 02-01 20:41:23 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 02-01 20:41:23 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 02-01 20:41:29 model_runner.py:867] Graph capturing finished in 7 secs.\n",
      "INFO 02-01 20:41:29 model_runner.py:867] Graph capturing finished in 7 secs.\n",
      "No.2 LLM Inderence start!No.0 LLM Inderence start!\n",
      "INFO 02-01 20:41:29 model_runner.py:867] Graph capturing finished in 7 secs.\n",
      "No.3 LLM Inderence start!\n",
      "第2部分：:   0%|          | 0/35 [00:00<?, ?it/s]长度过长，分为2个长度为10的sub batch\n",
      "长度过长，分为2个长度为10的sub batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No chat template is set for this tokenizer, falling back to a default class-level template. This is very error-prone, because models are often trained with templates different from the class default! Default chat templates are a legacy feature and will be removed in Transformers v4.43, at which point any code depending on them will stop working. We recommend setting a valid chat template before then to ensure that this model continues working without issues.\n",
      "No chat template is set for this tokenizer, falling back to a default class-level template. This is very error-prone, because models are often trained with templates different from the class default! Default chat templates are a legacy feature and will be removed in Transformers v4.43, at which point any code depending on them will stop working. We recommend setting a valid chat template before then to ensure that this model continues working without issues.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第3部分：:   0%|          | 0/35 [00:00<?, ?it/s]长度过长，分为2个长度为10的sub batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No chat template is set for this tokenizer, falling back to a default class-level template. This is very error-prone, because models are often trained with templates different from the class default! Default chat templates are a legacy feature and will be removed in Transformers v4.43, at which point any code depending on them will stop working. We recommend setting a valid chat template before then to ensure that this model continues working without issues.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-01 20:41:29 model_runner.py:867] Graph capturing finished in 7 secs.\n",
      "No.1 LLM Inderence start!\n",
      "第1部分：:   0%|          | 0/35 [00:00<?, ?it/s]长度过长，分为2个长度为10的sub batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No chat template is set for this tokenizer, falling back to a default class-level template. This is very error-prone, because models are often trained with templates different from the class default! Default chat templates are a legacy feature and will be removed in Transformers v4.43, at which point any code depending on them will stop working. We recommend setting a valid chat template before then to ensure that this model continues working without issues.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-01 20:41:29 model_runner.py:867] Graph capturing finished in 7 secs.\n",
      "No.4 LLM Inderence start!\n",
      "第4部分：:   0%|          | 0/35 [00:00<?, ?it/s]长度过长，分为2个长度为10的sub batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No chat template is set for this tokenizer, falling back to a default class-level template. This is very error-prone, because models are often trained with templates different from the class default! Default chat templates are a legacy feature and will be removed in Transformers v4.43, at which point any code depending on them will stop working. We recommend setting a valid chat template before then to ensure that this model continues working without issues.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-01 20:41:29 model_runner.py:867] Graph capturing finished in 6 secs.\n",
      "No.5 LLM Inderence start!\n",
      "第5部分：:   0%|          | 0/36 [00:00<?, ?it/s]长度过长，分为2个长度为10的sub batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No chat template is set for this tokenizer, falling back to a default class-level template. This is very error-prone, because models are often trained with templates different from the class default! Default chat templates are a legacy feature and will be removed in Transformers v4.43, at which point any code depending on them will stop working. We recommend setting a valid chat template before then to ensure that this model continues working without issues.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第3部分：:   3%|▎         | 1/35 [00:01<00:53,  1.58s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:   3%|▎         | 1/35 [00:01<00:57,  1.68s/it]长度过长，分为2个长度为10的sub batch长度过长，分为2个长度为10的sub batch\n",
      "\n",
      "第2部分：:   3%|▎         | 1/35 [00:01<01:04,  1.89s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:   3%|▎         | 1/36 [00:01<00:56,  1.62s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:   3%|▎         | 1/35 [00:01<01:03,  1.86s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:   6%|▌         | 2/35 [00:03<00:53,  1.63s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:   6%|▌         | 2/35 [00:03<00:53,  1.63s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:   6%|▌         | 2/35 [00:03<00:51,  1.58s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:   6%|▌         | 2/35 [00:03<00:49,  1.49s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:   6%|▌         | 2/35 [00:03<00:59,  1.79s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:   6%|▌         | 2/36 [00:03<01:02,  1.85s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:   9%|▊         | 3/35 [00:04<00:51,  1.60s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:   9%|▊         | 3/35 [00:05<00:54,  1.72s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:   9%|▊         | 3/35 [00:05<00:54,  1.72s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:   9%|▊         | 3/35 [00:05<00:54,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:   9%|▊         | 3/35 [00:04<00:53,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:   8%|▊         | 3/36 [00:05<00:59,  1.81s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  11%|█▏        | 4/35 [00:06<00:48,  1.56s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  11%|█▏        | 4/35 [00:06<00:52,  1.68s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  11%|█▏        | 4/35 [00:06<00:52,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  11%|█▏        | 4/35 [00:06<00:53,  1.72s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  11%|█▏        | 4/35 [00:07<00:55,  1.79s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  11%|█         | 4/36 [00:07<00:55,  1.74s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  14%|█▍        | 5/35 [00:07<00:46,  1.56s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  14%|█▍        | 5/35 [00:08<00:49,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  14%|█▍        | 5/35 [00:08<00:50,  1.69s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  14%|█▍        | 5/35 [00:08<00:50,  1.69s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  14%|█▍        | 5/35 [00:08<00:53,  1.79s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  14%|█▍        | 5/36 [00:08<00:52,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  17%|█▋        | 6/35 [00:09<00:47,  1.63s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  17%|█▋        | 6/35 [00:09<00:48,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  17%|█▋        | 6/35 [00:10<00:48,  1.69s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  17%|█▋        | 6/35 [00:10<00:48,  1.67s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  17%|█▋        | 6/35 [00:10<00:50,  1.74s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  17%|█▋        | 6/36 [00:10<00:49,  1.64s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  20%|██        | 7/35 [00:11<00:45,  1.62s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  20%|██        | 7/35 [00:11<00:45,  1.63s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  20%|██        | 7/35 [00:11<00:48,  1.72s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  20%|██        | 7/35 [00:11<00:48,  1.73s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  19%|█▉        | 7/36 [00:11<00:47,  1.62s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  20%|██        | 7/35 [00:12<00:50,  1.80s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  23%|██▎       | 8/35 [00:13<00:44,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  23%|██▎       | 8/35 [00:13<00:43,  1.59s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  23%|██▎       | 8/35 [00:13<00:46,  1.73s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  22%|██▏       | 8/36 [00:13<00:45,  1.62s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  23%|██▎       | 8/35 [00:13<00:45,  1.69s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  23%|██▎       | 8/35 [00:13<00:47,  1.77s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  26%|██▌       | 9/35 [00:14<00:41,  1.59s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  26%|██▌       | 9/35 [00:14<00:44,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  26%|██▌       | 9/35 [00:15<00:43,  1.68s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  25%|██▌       | 9/36 [00:15<00:44,  1.64s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  26%|██▌       | 9/35 [00:15<00:43,  1.68s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  26%|██▌       | 9/35 [00:15<00:44,  1.69s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  29%|██▊       | 10/35 [00:16<00:41,  1.65s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  29%|██▊       | 10/35 [00:16<00:42,  1.69s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  29%|██▊       | 10/35 [00:16<00:41,  1.67s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  29%|██▊       | 10/35 [00:17<00:41,  1.64s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  29%|██▊       | 10/35 [00:16<00:41,  1.67s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  28%|██▊       | 10/36 [00:17<00:45,  1.75s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  31%|███▏      | 11/35 [00:18<00:40,  1.68s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  31%|███▏      | 11/35 [00:18<00:40,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  31%|███▏      | 11/35 [00:18<00:37,  1.56s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  31%|███▏      | 11/35 [00:18<00:40,  1.68s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  31%|███       | 11/36 [00:18<00:41,  1.67s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  31%|███▏      | 11/35 [00:19<00:41,  1.74s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  34%|███▍      | 12/35 [00:19<00:38,  1.69s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  34%|███▍      | 12/35 [00:20<00:39,  1.73s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  34%|███▍      | 12/35 [00:19<00:36,  1.57s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  34%|███▍      | 12/35 [00:20<00:37,  1.63s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  34%|███▍      | 12/35 [00:20<00:40,  1.75s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  33%|███▎      | 12/36 [00:20<00:41,  1.73s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  37%|███▋      | 13/35 [00:21<00:35,  1.63s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  37%|███▋      | 13/35 [00:21<00:33,  1.51s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  37%|███▋      | 13/35 [00:21<00:37,  1.72s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  37%|███▋      | 13/35 [00:21<00:35,  1.62s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  37%|███▋      | 13/35 [00:22<00:37,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  36%|███▌      | 13/36 [00:22<00:39,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  40%|████      | 14/35 [00:23<00:34,  1.65s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  40%|████      | 14/35 [00:22<00:32,  1.57s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  40%|████      | 14/35 [00:23<00:35,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  40%|████      | 14/35 [00:23<00:34,  1.64s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  40%|████      | 14/35 [00:24<00:36,  1.74s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  39%|███▉      | 14/36 [00:23<00:38,  1.73s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  43%|████▎     | 15/35 [00:24<00:31,  1.55s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  43%|████▎     | 15/35 [00:24<00:33,  1.67s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  43%|████▎     | 15/35 [00:24<00:32,  1.64s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  43%|████▎     | 15/35 [00:25<00:34,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  43%|████▎     | 15/35 [00:26<00:35,  1.78s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  42%|████▏     | 15/36 [00:25<00:37,  1.78s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  46%|████▌     | 16/35 [00:26<00:29,  1.58s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  46%|████▌     | 16/35 [00:26<00:32,  1.72s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  46%|████▌     | 16/35 [00:26<00:33,  1.75s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  46%|████▌     | 16/35 [00:26<00:32,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  46%|████▌     | 16/35 [00:27<00:32,  1.69s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  44%|████▍     | 16/36 [00:27<00:35,  1.75s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  49%|████▊     | 17/35 [00:27<00:28,  1.61s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  49%|████▊     | 17/35 [00:28<00:29,  1.63s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  49%|████▊     | 17/35 [00:28<00:31,  1.75s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  49%|████▊     | 17/35 [00:28<00:33,  1.85s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  49%|████▊     | 17/35 [00:29<00:31,  1.75s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  47%|████▋     | 17/36 [00:29<00:33,  1.77s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  51%|█████▏    | 18/35 [00:29<00:28,  1.65s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  51%|█████▏    | 18/35 [00:29<00:28,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  51%|█████▏    | 18/35 [00:30<00:29,  1.73s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  51%|█████▏    | 18/35 [00:30<00:30,  1.81s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  54%|█████▍    | 19/35 [00:31<00:25,  1.61s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  51%|█████▏    | 18/35 [00:31<00:29,  1.75s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  50%|█████     | 18/36 [00:30<00:31,  1.73s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  54%|█████▍    | 19/35 [00:31<00:27,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  54%|█████▍    | 19/35 [00:32<00:27,  1.74s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  54%|█████▍    | 19/35 [00:32<00:29,  1.84s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  54%|█████▍    | 19/35 [00:32<00:27,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  57%|█████▋    | 20/35 [00:32<00:24,  1.62s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  53%|█████▎    | 19/36 [00:32<00:29,  1.75s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  57%|█████▋    | 20/35 [00:33<00:26,  1.74s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  57%|█████▋    | 20/35 [00:33<00:26,  1.74s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  57%|█████▋    | 20/35 [00:34<00:27,  1.82s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  60%|██████    | 21/35 [00:34<00:23,  1.65s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  57%|█████▋    | 20/35 [00:34<00:25,  1.72s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  56%|█████▌    | 20/36 [00:34<00:27,  1.72s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  60%|██████    | 21/35 [00:34<00:23,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  60%|██████    | 21/35 [00:35<00:23,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  60%|██████    | 21/35 [00:36<00:25,  1.80s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  60%|██████    | 21/35 [00:36<00:23,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  63%|██████▎   | 22/35 [00:36<00:21,  1.69s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  58%|█████▊    | 21/36 [00:36<00:25,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  63%|██████▎   | 22/35 [00:36<00:21,  1.68s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  63%|██████▎   | 22/35 [00:37<00:22,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  63%|██████▎   | 22/35 [00:37<00:21,  1.65s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  66%|██████▌   | 23/35 [00:37<00:19,  1.63s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  63%|██████▎   | 22/35 [00:37<00:23,  1.78s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  61%|██████    | 22/36 [00:37<00:23,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  66%|██████▌   | 23/35 [00:37<00:19,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  66%|██████▌   | 23/35 [00:38<00:20,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  69%|██████▊   | 24/35 [00:39<00:18,  1.65s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  66%|██████▌   | 23/35 [00:39<00:20,  1.68s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  69%|██████▊   | 24/35 [00:39<00:17,  1.59s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  64%|██████▍   | 23/36 [00:39<00:22,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  66%|██████▌   | 23/35 [00:40<00:22,  1.90s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  69%|██████▊   | 24/35 [00:40<00:18,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  69%|██████▊   | 24/35 [00:41<00:18,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  71%|███████▏  | 25/35 [00:41<00:16,  1.62s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  71%|███████▏  | 25/35 [00:41<00:16,  1.69s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  67%|██████▋   | 24/36 [00:41<00:20,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  69%|██████▊   | 24/35 [00:41<00:20,  1.86s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  71%|███████▏  | 25/35 [00:42<00:17,  1.74s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  71%|███████▏  | 25/35 [00:42<00:16,  1.63s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  74%|███████▍  | 26/35 [00:42<00:14,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  74%|███████▍  | 26/35 [00:42<00:14,  1.65s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  69%|██████▉   | 25/36 [00:42<00:19,  1.73s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  71%|███████▏  | 25/35 [00:43<00:18,  1.86s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  74%|███████▍  | 26/35 [00:44<00:15,  1.73s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  74%|███████▍  | 26/35 [00:44<00:15,  1.68s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  77%|███████▋  | 27/35 [00:44<00:13,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  77%|███████▋  | 27/35 [00:44<00:13,  1.64s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  72%|███████▏  | 26/36 [00:44<00:17,  1.72s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  77%|███████▋  | 27/35 [00:45<00:13,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  74%|███████▍  | 26/35 [00:45<00:17,  1.91s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  80%|████████  | 28/35 [00:45<00:11,  1.59s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  77%|███████▋  | 27/35 [00:46<00:13,  1.69s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  80%|████████  | 28/35 [00:46<00:12,  1.72s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  75%|███████▌  | 27/36 [00:46<00:15,  1.73s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  80%|████████  | 28/35 [00:47<00:11,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  77%|███████▋  | 27/35 [00:47<00:14,  1.84s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  83%|████████▎ | 29/35 [00:47<00:09,  1.56s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  80%|████████  | 28/35 [00:48<00:11,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  83%|████████▎ | 29/35 [00:48<00:10,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  78%|███████▊  | 28/36 [00:48<00:13,  1.74s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  83%|████████▎ | 29/35 [00:49<00:10,  1.67s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  86%|████████▌ | 30/35 [00:48<00:07,  1.56s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  80%|████████  | 28/35 [00:49<00:13,  1.87s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  86%|████████▌ | 30/35 [00:49<00:08,  1.69s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  83%|████████▎ | 29/35 [00:49<00:10,  1.77s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  81%|████████  | 29/36 [00:49<00:11,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  86%|████████▌ | 30/35 [00:50<00:08,  1.72s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  89%|████████▊ | 31/35 [00:50<00:06,  1.65s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  89%|████████▊ | 31/35 [00:51<00:06,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  83%|████████▎ | 29/35 [00:51<00:11,  1.90s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  83%|████████▎ | 30/36 [00:51<00:09,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  86%|████████▌ | 30/35 [00:51<00:09,  1.80s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  89%|████████▊ | 31/35 [00:52<00:06,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  91%|█████████▏| 32/35 [00:52<00:04,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  91%|█████████▏| 32/35 [00:53<00:05,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  86%|████████▌ | 30/35 [00:53<00:09,  1.92s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  86%|████████▌ | 31/36 [00:52<00:08,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  89%|████████▊ | 31/35 [00:53<00:07,  1.89s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  91%|█████████▏| 32/35 [00:54<00:05,  1.71s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  94%|█████████▍| 33/35 [00:54<00:03,  1.66s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  94%|█████████▍| 33/35 [00:54<00:03,  1.72s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  89%|████████▉ | 32/36 [00:54<00:06,  1.68s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  89%|████████▊ | 31/35 [00:55<00:07,  1.91s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：:  91%|█████████▏| 32/35 [00:55<00:05,  1.92s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  94%|█████████▍| 33/35 [00:56<00:03,  1.74s/it]长度过长，分为2个长度为10的sub batch\n",
      "第4部分：:  97%|█████████▋| 34/35 [00:55<00:01,  1.68s/it]长度过长，分为2个长度为10的sub batch\n",
      "第3部分：:  97%|█████████▋| 34/35 [00:56<00:01,  1.69s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  91%|█████████▏| 32/35 [00:56<00:05,  1.89s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  92%|█████████▏| 33/36 [00:56<00:05,  1.77s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：:  97%|█████████▋| 34/35 [00:57<00:01,  1.70s/it]长度过长，分为2个长度为10的sub batch\n",
      "长度过长，分为2个长度为10的sub batch\n",
      "第4部分：: 100%|██████████| 35/35 [00:57<00:00,  1.64s/it]\n",
      "第3部分：: 100%|██████████| 35/35 [00:58<00:00,  1.67s/it]\n",
      "第5部分：:  94%|█████████▍| 34/36 [00:58<00:03,  1.75s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  94%|█████████▍| 33/35 [00:58<00:03,  1.92s/it]长度过长，分为2个长度为10的sub batch\n",
      "第0部分：: 100%|██████████| 35/35 [00:59<00:00,  1.70s/it]\n",
      "第2部分：:  97%|█████████▋| 34/35 [00:59<00:01,  1.86s/it]长度过长，分为2个长度为10的sub batch\n",
      "第5部分：:  97%|█████████▋| 35/36 [01:00<00:01,  1.79s/it]长度过长，分为2个长度为10的sub batch\n",
      "第1部分：:  97%|█████████▋| 34/35 [01:00<00:01,  1.91s/it]长度过长，分为2个长度为10的sub batch\n",
      "第2部分：: 100%|██████████| 35/35 [01:01<00:00,  1.75s/it]\n",
      "第5部分：: 100%|██████████| 36/36 [01:02<00:00,  1.72s/it]\n",
      "第1部分：: 100%|██████████| 35/35 [01:02<00:00,  1.80s/it]\n",
      "Model inference finished！\n"
     ]
    }
   ],
   "source": [
    "for model_name in scopes:\n",
    "    print(f\"{model_name}开始！\")\n",
    "    kwargs = {}\n",
    "    prompt_list_from_path = os.path.join( _ROOT_PATH, \"test/CPL_dynamic/v1/counter_prompt_list_hybrid_rag.pickle\")\n",
    "    kwargs[\"local_or_remote\"] = \"local\"\n",
    "    kwargs[\"server_or_reader\"] = \"reader\"\n",
    "    kwargs[\"model_name\"] = model_name\n",
    "    kwargs[\"gpu_list\"] = \"0,1,2,3,4,5\"\n",
    "    kwargs[\"local_engine\"] = \"vllm\"\n",
    "    if prompt_list_from_path != None:\n",
    "        kwargs[\"prompt_list_from_path\"] = prompt_list_from_path\n",
    "        kwargs[\"predict_list_to_path\"] = prompt_list_from_path.replace( \"prompt_list\", f\"predict_list_{model_name}\") \n",
    "        kwargs[\"sample_little\"] = None\n",
    "    inferencer = Inferencer( kwargs )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
