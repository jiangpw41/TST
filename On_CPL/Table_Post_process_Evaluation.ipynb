{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from wayne_utils import load_data, save_data\n",
    "_ROOT_PATH = \"workspace/TKGT\"\n",
    "sys.path.insert( 0, _ROOT_PATH )\n",
    "_Data_path = os.path.join( _ROOT_PATH, \"data/CPL/dynamic\")\n",
    "version_dir = os.path.join( _ROOT_PATH, \"test/CPL_dynamic/v1\")\n",
    "\n",
    "label_lists = load_data( os.path.join( version_dir, \"label_lists.pickle\"), \"pickle\")\n",
    "prefix_lists = load_data( os.path.join( version_dir, \"table_prefix_list.pickle\"), \"pickle\")\n",
    "prompt_lists = load_data( os.path.join( version_dir, \"table_prompt_list.pickle\"), \"pickle\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPL_dynamic_tabel_Chinese-Mistral-7B-Instruct-v0.1-4epoch']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list_table = [\n",
    "    \"ChatGLM3-6B\",\n",
    "    \"Qwen1.5-7B-Chat\",\n",
    "    \"Baichuan2-7B-Chat\",\n",
    "    \"Chinese-Mistral-7B-Instruct-v0.1\",\n",
    "    \"Qwen2.5-0.5B\",\n",
    "    \"CPL_dynamic_tabel_Qwen1.5-7B-Chat-4epoch\",\n",
    "    \"CPL_dynamic_tabel_ChatGLM3-6B-4epoch\",\n",
    "    \"CPL_dynamic_tabel_Chinese-Mistral-7B-Instruct-v0.1-4epoch\",\n",
    "]\n",
    "scopes = model_list_table[7:]\n",
    "scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer( text ):\n",
    "    if text.strip() == \"\":\n",
    "        return None\n",
    "    elif \"not found\" in text.lower() or \"notfound\" in text.lower() or \"抱歉\" in text:\n",
    "        return None\n",
    "    else:\n",
    "        return text.strip()\n",
    "\n",
    "def post_process( predicts, prefixs, prompts):\n",
    "    \"\"\"处理单个文件\"\"\"\n",
    "    if len( predicts ) != len( prefixs ):\n",
    "        raise Exception( f\"Predict和prefix列表长度不一致：{len( predicts )} vs {len( prefixs )}\" )\n",
    "    temp = set()\n",
    "    for i in range( len(predicts) ):\n",
    "        entity_type, field = prefixs[i][0], prefixs[i][1]\n",
    "        predict = predicts[i]\n",
    "        try:\n",
    "            ans = get_answer( predict )\n",
    "        except:\n",
    "            raise Exception( f\"{i} {predict}\" )\n",
    "        if ans != None and \"\\n相关上下文：[]\" not in prompts[i]:\n",
    "            temp.add( (entity_type, field, ans))\n",
    "    return temp\n",
    "\n",
    "def ratio_post( value ):\n",
    "    if not value.strip()[-1].isdigit():\n",
    "        value = value[:-1]\n",
    "    if value == \"\" or not value[-1].isdigit():\n",
    "        return None\n",
    "    if \"%\" in value:\n",
    "        value = value.split(\"%\")[0].strip()\n",
    "    try:\n",
    "        float_value = float( value )\n",
    "    except:\n",
    "        return None\n",
    "    if float_value < 0.99:\n",
    "        ret = str( float_value * 100)\n",
    "    elif float_value >100:\n",
    "        return None\n",
    "    else:\n",
    "        ret = str(float_value)\n",
    "    if ret.endswith(\".0\"):\n",
    "        ret = ret[:-2]\n",
    "    return ret\n",
    "\n",
    "from datetime import datetime\n",
    "def date_post(date_str):\n",
    "    # 尝试不同的日期格式进行解析\n",
    "    date_formats = [\n",
    "        \"%Y/%m/%d\",  # 2012/2/2\n",
    "        \"%Y.%m.%d\",  # 2012/2/2\n",
    "        \"%Y年%m月%d日\",  # 2000年2月2日\n",
    "        \"%Y年-%m月-%d日\",  # 2000年-2月-2日\n",
    "        \"%Y-%m-%d\"  # 2000-2-2\n",
    "    ]\n",
    "    \n",
    "    for date_format in date_formats:\n",
    "        try:\n",
    "            # 尝试使用当前格式解析日期\n",
    "            date_obj = datetime.strptime(date_str, date_format)\n",
    "            # 格式化为统一的\"xxxx年xx月xx日\"格式\n",
    "            formatted_date = date_obj.strftime(\"%Y年%m月%d日\")\n",
    "            return formatted_date\n",
    "        except ValueError:\n",
    "            # 如果解析失败，继续尝试下一个格式\n",
    "            continue\n",
    "    \n",
    "    # 如果所有格式都尝试失败，返回错误信息\n",
    "    return None\n",
    "\n",
    "def split_names( value ):\n",
    "    if \"、\" in value:\n",
    "        sep = \"、\"\n",
    "    elif \"，\" in value:\n",
    "        sep = \"，\"\n",
    "    elif \",\" in value:\n",
    "        sep = \",\"\n",
    "    else:\n",
    "        sep = None\n",
    "\n",
    "    if sep == None:\n",
    "        return value.strip()\n",
    "    else:\n",
    "        ret = []\n",
    "        names = value.split( sep )\n",
    "        for name in names:\n",
    "            ret.append( name.strip() )\n",
    "        return ret\n",
    "\n",
    "def value_type_unify( value_set ):\n",
    "    \"\"\"\n",
    "    value_list: 预测或label\n",
    "    three: 是否是三元组\n",
    "    \"\"\"\n",
    "    temp = set()\n",
    "    # 遍历单个文档的元组集合\n",
    "    for item in value_set:\n",
    "        # 获取每个元组的组成\n",
    "        entity, field, value = item[0], item[1], item[2]\n",
    "        if field == \"姓名名称\":\n",
    "            names = split_names( value )\n",
    "            if isinstance( names, list):\n",
    "                for name in names:\n",
    "                    temp.add( (entity, field, name) )\n",
    "            else:\n",
    "                temp.add( (entity, field, names) )\n",
    "        elif \"约定情况\" in field:\n",
    "            if \"口头\" in value:\n",
    "                temp.add( (entity, field, \"口头约定\") )\n",
    "            elif \"书面\" in value:\n",
    "                temp.add( (entity, field, \"书面约定\") )\n",
    "            elif \"未\" in value:\n",
    "                temp.add( (entity, field, \"未约定\") )\n",
    "        elif \"（百分比或元）\" in field:\n",
    "            value = ratio_post( value )\n",
    "            if value != None:\n",
    "                temp.add( ( entity, field, value ) )\n",
    "        elif \"日期\" in field or \"时间\" in field:\n",
    "            value = date_post( value )\n",
    "            if value != None:\n",
    "                temp.add( ( entity, field, value ) )\n",
    "        else:\n",
    "            temp.add( ( entity, field, value ) )\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in scopes:\n",
    "    predict_lists = load_data( os.path.join( version_dir, f\"table_predict_list_{model_name}.pickle\"), \"pickle\")\n",
    "    predict_post = []\n",
    "    for index in range( len(prefix_lists)):\n",
    "        #index = 1           # doc\n",
    "        temp_set = set( )\n",
    "        for inner_index in range( len(prefix_lists[index])):\n",
    "            # inner_index = 3     # prefix\n",
    "            entity, top_field, number = prefix_lists[index][inner_index][0], prefix_lists[index][inner_index][1], prefix_lists[index][inner_index][2]\n",
    "            predict = predict_lists[index][inner_index]\n",
    "\n",
    "            if \"\\n回答：\" in predict:\n",
    "                predict = predict.split( \"\\n回答：\")[1].strip()\n",
    "            if \"如下：\" in predict:\n",
    "                predict = predict.split( \"如下：\")[1].strip()\n",
    "            labels_subset = []\n",
    "            # 遍历该文档的每个三元组，将于目前prefix契合的放入子集\n",
    "            for item in label_lists[index]:\n",
    "                total_field = item[1]\n",
    "                if entity == item[0] and top_field in total_field:          # 这个标签是和当前Prefix匹配的\n",
    "                    labels_subset.append( item )\n",
    "            # 遍历子集\n",
    "            for item in labels_subset:\n",
    "                total_field = item[1]\n",
    "                if \"期限的还款日期\" in total_field or \"实际发生时间\" in total_field:\n",
    "                    \n",
    "                    date_line = item[2]\n",
    "                    \n",
    "                    try:\n",
    "                        if \"、\" in date_line:\n",
    "                            date_line = date_line.split(\"、\")[0].strip()\n",
    "                        try:\n",
    "                            year, month, day = date_line.split(\"-\")\n",
    "                        except:\n",
    "                            year, month, day = date_line.split(\".\")\n",
    "                    except:\n",
    "                        if item[2] == \"借条\" or \"被告曾国印向原告借款50000元\" in item[2] or \"6/？\" in item[2] or \"2017年5月底\" in item[2] or '43097' in item[2] or \\\n",
    "                        '农历2015/12/3' in item[2] or '定于2018年10月21日之前归还' in item[2] or '40487' in item[2] : \n",
    "                            pass\n",
    "                        else:\n",
    "                            raise Exception( f\"label中的日期格式不对{date_line} {item}\")\n",
    "                    if date_line in predict or f\"{year}年{month}月{day}日\" in predict:\n",
    "                        temp_set.add( (entity, total_field, date_line) )\n",
    "                elif \"的金额（元）\" in total_field:\n",
    "                    money = item[2]\n",
    "                    if money in predict:\n",
    "                        temp_set.add( (entity, total_field, money) )\n",
    "                    elif money.endswith(\"0000\"):\n",
    "                        wan_yuan = money[-4]+\"万\"\n",
    "                        if wan_yuan in predict:\n",
    "                            temp_set.add( (entity, total_field, money) )\n",
    "                elif \"数值（百分比或元）\" in total_field:\n",
    "                    ratio = str(item[2])\n",
    "                    new_ration = ratio_post( ratio )\n",
    "                    if ratio in predict or str(new_ration) in predict:\n",
    "                        temp_set.add( (entity, total_field, ratio) )\n",
    "                elif \"约定情况\" in total_field:\n",
    "                    approve = item[2]\n",
    "                    for type_ in [\"口头\", \"书面\"]:\n",
    "                        if type_ in approve and type_ in predict:\n",
    "                            temp_set.add( (entity, total_field, approve) )\n",
    "                            break\n",
    "                else:\n",
    "                    names_or_content = item[2]\n",
    "                    if names_or_content in predict:\n",
    "                        temp_set.add( (entity, total_field, names_or_content) )\n",
    "\n",
    "        predict_post.append( temp_set )\n",
    "    new_predict_list = []\n",
    "    new_label_list = []\n",
    "    for i in range(len(predict_post)):\n",
    "        new_predict_list.append( value_type_unify( predict_post[i] ) )\n",
    "        new_label_list.append(   value_type_unify( label_lists[i] ) )\n",
    "    save_data( (new_label_list, new_predict_list), os.path.join( version_dir, f\"table_predict_lists_filter_{model_name}.pickle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [00:00<00:00, 1525.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row header: precision = 100.00; recall = 99.53; f1 = 99.72\n",
      "Col header: precision = 100.00; recall = 80.30; f1 = 87.65\n",
      "Non-header cell: precision = 100.00; recall = 78.63; f1 = 87.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [00:01<00:00, 210.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row header: precision = 100.00; recall = 99.59; f1 = 99.76\n",
      "Col header: precision = 100.00; recall = 85.10; f1 = 90.83\n",
      "Non-header cell: precision = 100.00; recall = 80.89; f1 = 88.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [03:06<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row header: precision = 100.00; recall = 99.63; f1 = 99.78\n",
      "Col header: precision = 100.00; recall = 87.79; f1 = 92.55\n",
      "Non-header cell: precision = 100.00; recall = 82.81; f1 = 89.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluation.Text2table.evaluate import eval_main\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "for model_name in scopes:    \n",
    "\n",
    "    loaded_pair_list = load_data( os.path.join( version_dir, f\"table_predict_lists_filter_{model_name}.pickle\"), \"pickle\")\n",
    "    \n",
    "    results_save_path = os.path.join( _ROOT_PATH, \"/home/jiangpeiwen2/jiangpeiwen2/TKGT/evaluation/CountCPL/results.json\")\n",
    "    eval_main( f\"CPL_dynamic_static_baseline_{model_name}\", loaded_pair_list, results_save_path, \"multi_entity\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tkgt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
